---
title: '파이썬으로 웹 크롤링하기'
date: '2019-11-15'
excerpt: '파이썬(Python)을 사용하여 웹 페이지를 크롤링하고 그 결과를 저장하기'
categories: 'python'
tags: ['python', 'html']
---

## 개요
---

>크롤링(Clawling)

소프트웨어 따위가 웹을 돌아다니며 유용한 정보를 찾아 특정 데이터베이스로 수집해 오는 작업. 또는 그러한 기술.


네이버 사전에서는 위와 같이 크롤링에 대해서 설명하고 있습니다. 크롤링은 간단히 말해 **인터넷에 있는 정보를 수집하는 작업**을 말합니다.<br>

인터넷에는 수많은 정보들이 존재합니다. 우리들은 필요한 정보가 있으면 그 정보를 찾기위해 인터넷을 탐험합니다. 하지만 특정한 정보를 내 앞으로 가져오게 한다면 인터넷을 탐험하는 수고를 덜 수 있을 것입니다.

이번 포스트는 파이썬(Python)을 사용하여 웹 상의 정보(HTML)를 수집하고(파싱), 저장하는 방법에 대해서 설명합니다.
<br>
<br>

## 준비
---
1. Python 3.7.4

   [이곳](https://www.python.org/downloads/)에서 내려받을 수 있습니다.
<br>
<br>
2. Requests, BeautifulSoup4

   `Requests`와 `BeautifulSoup4`는 웹 사이트를 크롤링 하기 위한 **필수 라이브러리**입니다. `Requests` 라이브러리가 웹의 정보를 가져오는데(파싱)에 의미가 강하다면 `BeautifulSoup4`는 Python이 그 정보를 잘 가공할 수 있게 합니다.
   `Requests`와 `BeautifulSoup4`는 다음과 같이 설치 할 수 있습니다.

   1\. 명령 프롬프트(`CMD`)를 **관리자 권한**으로 실행하고 다음과 같이 명령어를 입력합니다.

   ```
   pip install --upgrade pip
   ```

   <div class = "notice--info">pip 업그레이드가 되있다면 위 과정은 생략하여도 무방합니다.
   </div>

   2\. 업그레이드가 완료되었다면 다음과같이 명령어를 입력하여 `Requests`를 설치합니다.

   ```
   pip install Requests
   ```

   3\. 명령 프롬프트에 이어서 다음과 같이 명령어를 입력하여 `BeautifulSoup`를 설치합니다.

   ```
   pip install BeautifulSoup4
   ```
<br>
<br>
3. 여러분의 Python Editor는 웹 크롤링을 위한 준비를 모두 마쳤습니다.✔

## 실행
---
예제로 아래 네이버 금융의 국내증시 페이지를 파이썬을 통해 크롤링 해보겠습니다.

![파이썬으로 웹 크롤링하기_1](https://i.imgur.com/C0LFhky.png)

```python
# Requests와 BeautifulSoup4 라이브러리 임포트
import requests
import bs4

# GET 방식으로 해당 웹 사이트에 접근(Request)
target = requests.get('https://finance.naver.com/sise/')

# HTML 소스 가져오기
html = target.text

# txt 파일로 저장
f = open("C://Users/terada/국내 증시.html", 'w')
f.write(html)
f.close()
```

위 코드를 실행하여 저장된 txt 파일을 확인해보면, HTML 코드가 텍스트 형식으로 저장되어있는 것을 확인할 수 있습니다.
실제로 확장자를 `.html` 로 변경해서 브라우저에서 확인해보면 다음과 같은 결과가 출력됩니다.

![파이썬으로 웹 크롤링하기_3](https://i.imgur.com/rr5hL4x.png)

사이트의 서식(CSS)은 조금 다르지만 페이지의 정보는 완벽하게 복제한 것을 확인할 수 있습니다.

위에서 실행한 코드는 페이지의 전체 html을 가져오고있습니다.
그런데 저는 이 페이지의 우측의 `인기 검색 종목`만 크롤링 하려고 합니다. 웹 페이지에서 내가 필요한 정보만 크롤링하기 위해서는 어떻게 해야 할까요?

이하에서는 BeautifulSoup4를 사용하여 페이지에서 필요한 요소를 크롤링하는 법에 대해서 설명합니다.

다시 크롤링 하고 싶은 페이지로 돌아가, 개발자 모드(Ctrl+Shift+I)로 `인기 검색 종목`을 나타내는 페이지의 요소를 확인합니다.

![파이썬으로 웹 크롤링하기_4](https://i.imgur.com/ty0EL9G.png)

인기 검색 종목은 class 'rgt'라는 div 내부의 id 'poplularItemList'에 저장되어 있습니다.
HTML의 요소나 구조에 대해서 깊게 이해할 필요는 없습니다. 우리는 그저 필요한 요소를 **오른쪽 클릭 - COPY - Copy Selector** 하면 됩니다.
그러면 클립보드에 다음과 같은 코드가 복사됩니다.

```css
#popularItemList
```

이것을 **CSS 선택자**라고 합니다. 웹 페이지 내부에서 요소를 특정할 수 있는 일종의 고유한 이름입니다.

이제 다음과 같이 코드를 작성하면 HTML 내부의 원하는 내용만 크롤링 할 수 있습니다.

```python
# sys, Requests, BeautifulSoup4 라이브러리 임포트
import requests
import bs4
import sys

# GET 방식으로 해당 웹 사이트에 접근(Request)
target = requests.get('https://finance.naver.com/sise/')

# HTML 소스 가져오기
html = target.text

# BeautifulSoup가 html을 조작할 수 있도록 설정
soup = bs4.BeautifulSoup(html, 'html.parser')

# Copy Selector를 통해 페이지 내 특정 요소를 획득
item = soup.select(
    '#popularItemList'
)

# 출력될 결과를 HTML 파일로 저장
sys.stdout = open('C://Users/terada/인기 검색 종목.html','w')
print(item)
```

<div class='notice--info'>출력 결과가 반영되는데 약간의 시간이 소요됩니다.
</div>

결과는 다음과 같습니다.

![파이썬으로 웹 크롤링하기_5](https://i.imgur.com/OMKxgtX.png)

## 마치며

BeautifulSoup4 라이브러리에 대해 조금 더 공부한다면 더 세련되고, 정제된 데이터를 획득할 수 있습니다. Python은 다양한 라이브러리 생태계를 제공하고 있습니다. 필요에 따라서는 csv파일로 저장하여 excel에서 활용하거나, 다른 라이브러리와 함께 창의적인 방법으로 데이터를 이용할 수 있습니다. 세상은 상상력으로 만들어지니까요. 이것으로 무엇을 만들지는 여러분들의 몫입니다.😂

